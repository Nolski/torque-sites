#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Perform some one-time fixes to the MacArthur Foundation 100&Change CSV file
#
# This is necessary because not everything can be addressed with the
# 'sanitize' script.  The 'sanitize' script isn't aware of CSV rows or
# columns; it just treats the whole CSV file as a normal text file.
# But for, e.g., fixing the YouTube links (see features.org for more),
# we really need a one-time transformation that knows what cell it's
# operating on.
#
# Copyright (C) 2017 Open Tech Strategies, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

##########################################################################
#                                                                        #
#   NOTE: This code is highly specific to the needs of the MacArthur     #
#   Foundation and is unlikely to be correct for your CSV.  It is        #
#   open source software, so please modify it to suit your needs.        #
#                                                                        #
##########################################################################

__doc__ = """\
Compose all of the MacArthur Foundation 2019 Proposal CSV files.

Usage:

  $ compose-csvs \\
       --proposals-csv=PROPOSALS_CSV \\
       --admin-review-csv=ADMIN_REVIEW_CSV \\
       --judge-evaluation-csv=JUDGE_EVALUATION_CSV \\
       --extra-category-file=EXTRA_CATEGORY_FILE

Command-line options:
  --proposals-csv FILE          FILE is a csv FILE representing the bulk
                                of the proposal information

  --admin-review-csv FILE       FILE is a csv FILE representing which applications
                                in PROPOSALS_CSV should be included

  --judge-evaluation-csv FILE   FILE is a csv FILE with a many to one relationshp
                                between judges and the proposals they evaluated,
                                with the extra data being their evaluation

  --pare N                      Reduce the nuber of tiems to 1/N rows, for quick
                                testing and development
"""

import csv
import getopt
import re
import io
import sys
import warnings
import string
import os
from bs4 import BeautifulSoup

def collapse_replace(string, old, new):
    "Return STRING, with OLD repeatedly replaced by NEW until no more OLD."
    while string.find(old) != -1: 
        string = string.replace(old, new)
    return string

def weaken_the_strong(html):
    """Strip any meaningless <strong>...</strong> tags from HTML.
    HTML is a Unicode string; the return value is either HTML or a new
    Unicode string based on HTML.

    If <strong> tags cover everything in HTML, remove the tags.  But if
    <strong> tags are used only sometimes, maybe they're meaningful, so
    leave them.  Basically, we want to make strength great again."""
    # If there's no strength here, move on.
    if not "<strong>" in html:
        return html
    
    # Remove the stuff inside strong tags
    soup = BeautifulSoup(html, "html.parser")
    while "<strong>" in str(soup):
        soup.strong.extract()

    # Check whether the non-bold stuff is more than just tags and
    # punctuation.  If not, all the important stuff was bold, so strip
    # bold and return.
    if re.sub(r"\W", "", soup.get_text()) == "":
        return re.sub("</?strong>", "", html)

    # OTOH, if the non-bold stuff contained letters or numbers, maybe
    # there's real content there, which means the html was a mix of
    # bold and non-bold text.  Better to leave it alone.
    return html

def form_well(html):
    """Return a well-formed version of HTML with dangling tags closed.
    Some of the input includes tables that cut off without closing
    tags; some entries leave <td> tags open too."""
    # Parse html and suppress warnings about urls in the text
    warnings.filterwarnings("ignore",
                            category=UserWarning, module='bs4')
    soup = BeautifulSoup(html, "html.parser")

    # Return well-formed html as a soup object
    return soup

# Used in converting "<foo>&nbsp;<bar>" and "</foo>&nbsp;<bar>"
# to "<foo> <bar>" and "</foo> <bar>" respectively.  (Those particular
# instances of "&nbsp;" in the data are not very convincing, and they
# create noise when we're looking for unnecessary escaping elsewhere.)
intertag_nbsp_re = re.compile('(?m)(</?[a-z]+>)&nbsp;(<[a-z]+>)')

# Matches Unicode 8226 (U+2022) at the beginning of a line,
# which is something that applicants do in a lot of fields.
bullets_re = re.compile("^â€¢", re.MULTILINE)

def fix_cell(cell):
    """Return a cleaned up version of the CELL that will work well
    with mediawiki, mainly through text subsitution."""
    # A straight-up HTML-unescaping might be the right thing
    # (i.e., cell = html_parser.unescape(cell) below)
    # in the long run, but for now, let's do the same limited
    # set of unescapings the original 'sanitize' script did:
    cell = cell.replace('&amp;', '&')
    cell = cell.replace('&lt;', '<')
    cell = cell.replace('&gt;', '>')
    # The rest should be recursively collapsing replacements:
    cell = collapse_replace(cell, '\t', ' ')
    cell = collapse_replace(cell, '&nbsp;&nbsp;', '&nbsp;')
    cell = collapse_replace(cell, '&nbsp; ', ' ')
    cell = collapse_replace(cell, ' &nbsp;', ' ')
    cell = collapse_replace(cell, '&nbsp;</', '</')
    cell = collapse_replace(cell, '\\"', '"')
    cell = re.sub(intertag_nbsp_re, '\\1 \\2', cell)

    soup = form_well(cell)
    cell = weaken_the_strong(str(soup))

    # The parsing for lists requires an asterisk at the start
    # of the line, but some entries use bullets. This regex
    # swaps the bullets for asterisks.
    cell = bullets_re.sub("*", cell)

    # We don't want to have extra new lines added at the beginning or end
    # because that could make the wiki formatting odd
    cell = cell.strip()

    return cell

def categorize_sdg(cell, extra_cats):
    """Change the CELL to have wiki markup for the comma separated categories
    present.  Achieve this by adding in wiki markup to the output spreadsheet
    so that csv2wiki passes them through."""

    categories = cell.split(",")

    new_cell = ''
    for category in categories:
        category = category.strip()
        if category not in extra_cats:
            extra_cats.append(category)
        new_cell += '[[:Category:' + category + '|' + category + ']]\n'
        new_cell += '* [[Category:' + category + ']]\n'

    return new_cell

def categorize_cell(cell, extra_cats):
    """Change the CELL to have wiki markup for the category represented by
    the data in the cell, if there's data in the cell.  Add the category
    to the EXTRA_CATS"""

    cell = cell.strip()

    if cell == 'NULL':
        return cell;

    if cell == '':
        return cell;

    new_cell = ''
    if cell not in extra_cats:
        extra_cats.append(cell)
    new_cell += '[[:Category:' + cell + '|' + cell + ']]'
    new_cell += '[[Category:' + cell + ']]\n'

    return new_cell

def print_csv(header_row, rows):
    """Print the HEADER_ROW and ROWS to stdout via csv"""

    csv_writer = csv.writer(sys.stdout,
                            delimiter=',', quotechar='"', lineterminator="\n")

    csv_writer.writerow(header_row)
    for row in rows:
        csv_writer.writerow(row)

def process_judge_data(csv_reader):
    """Takes a CSV_READER representing judge data in a spreadsheet and
    turns that into a dict of dicts in the following form:

      JUDGE_DATA[app_id] = {
        overall_score_rank_normalized: string,
        sum_of_scores_normalized: string,
        traits: array of TRAIT (below)
      }

      TRAIT = {
        name: string,
        score_normalized: string
        judge_comments: concatenated string
      }

    The judge data coming in has many judge comments in their own row to one
    application.  There are N traits, and M judges per trait, with things like
    overall_score_rank_normalized being duplicated for all NxM rows.

    The scores for the traits are added up based here rather than in the
    spreasheet.  Then, judge comments are concatenated for that trait.
    """

    judge_data = {}

    next(csv_reader)
    for row in csv_reader:
        application_id = row[3]
        if not application_id in judge_data:
            judge_data[application_id] = {
                    "overall_score_rank_normalized": row[9],
                    "sum_of_scores_normalized": row[11],
                    "traits": [],
                    }

        judge_datum = judge_data[application_id]

        found = False

        for trait in judge_datum["traits"]:
            if trait["name"] == row[15]:
                found = True
                trait["score_normalized"] += float(row[13])
                trait["judge_comments"] += "\n\n* " + row[14]

        if not found:
            judge_datum["traits"].append({
                    "name": row[15],
                    "score_normalized": float(row[13]),
                    "judge_comments": "\n\n* " + row[14]
                })

    return judge_data

def wiki_escape_page_title(s):
    """Return a wiki-escaped version of STRING."""
    for c in ["#", "<", ">", "[", "]", "{", "|", "}",]:
        if s.find(c) != -1:
            s = s.replace(c, "-")
    while len(bytes(s, "UTF-8")) > 255:
        s = s[:-1]
    return s

def compose_csvs(proposals, admin_review, judge_eval, extra_category_file,
        attachments_file, attachments_dir, pare=None):
    """Write a composed version of PROPOSALS (a CSV file), ADMIN_REVIEW
    (a CSV file), and JUDGE_EVAL (a CSV file) to standard out.

    PROPOSALS, ADMIN_REVIEW, and JUDGE_EVAL are all filenames.  They
    represent a full list of proposals, a list of accepted proposals,
    and evaluation on those proposals, respectively

    EXTRA_CATEGORY_FILE and ATTACHMENTS_FILE are locations that compose-csvs
    will write to disk for csv2wiki to pick up later to add categories and
    attachments to the wiki.

    ATTACHMENTS_DIR is the directory to look in for attachments.

    If PARE is not None, it is a positive integer indicating that only
    1 of every PARE entries should be processed, and the others skipped."""
    try:
        proposals_reader = csv.reader(open(proposals, encoding='utf-8'),
                                      delimiter=',', quotechar='"')
        admin_review_reader = csv.reader(open(admin_review, encoding='utf-8'),
                                         delimiter=',', quotechar='"')
        judge_eval_reader = csv.reader(open(judge_eval, encoding='utf-8'),
                                       delimiter=',', quotechar='"')
    except UnicodeDecodeError:
        sys.stderr.write("fix-csv expects utf-8-encoded unicode, not whatever is in this csv file.\n")
        sys.exit(-1)

    header_row = next(proposals_reader)

    # We only accept applications if they're one of the rows in the
    # admin_review csv, which has an "Application #" column (3),
    # which matches a "Review #" column in the proposals (3)
    # and for which the "Status" column (7) is valid
    next(admin_review_reader) # Don't look at header
    acceptable_application_numbers = [ row[3] for row in admin_review_reader if row[7].lower() == "valid" ]

    judge_data = process_judge_data(judge_eval_reader)

    row_num = 0
    new_rows = []
    extra_cats = []
    attachments_to_add = []
    for row in proposals_reader:
        if row[3] not in acceptable_application_numbers:
            continue

        row_num += 1  # first row here is row 1 (the header row was row 0) 
        if pare is not None and row_num % pare != 0:
            continue

        new_row = []
        num_fixed_cells = 0
        for cell in row:
            fixed_cell = fix_cell(cell)
            if fixed_cell != cell:
                num_fixed_cells += 1
            new_row.append(fix_cell(cell))

        # Mutate the rows to add special wiki markup for categorization of pages.
        # This is special to the 2019 run.  We need to save the extra_categories
        # so that csv2wiki will make them
        new_row[128] = categorize_sdg(row[128], extra_cats)
        new_row[68] = categorize_cell(row[68], extra_cats)
        new_row[74] = categorize_cell(row[74], extra_cats)
        new_row[80] = categorize_cell(row[80], extra_cats)
        new_row[98] = categorize_cell(row[98], extra_cats)
        new_row[104] = categorize_cell(row[104], extra_cats)
        new_row[110] = categorize_cell(row[110], extra_cats)
        new_row[116] = categorize_cell(row[116], extra_cats)
        new_row[122] = categorize_cell(row[122], extra_cats)

        if row[3] in judge_data:
            new_row.extend([
                judge_data[row[3]]["overall_score_rank_normalized"],
                judge_data[row[3]]["sum_of_scores_normalized"] ])

            for trait in judge_data[row[3]]["traits"]:
                new_row.append(trait["name"])
                new_row.append("{0:.1f}".format(trait["score_normalized"]))
                new_row.append(trait["judge_comments"])
        else:
            new_row.extend(["", ""])

            # for now, we know that there are 4 traits
            for _ in range(4):
                new_row.extend(["", "", ""])

        attachments_str = ""
        if attachments_dir is not None:
            application_attachment_dir = os.path.join(attachments_dir, row[3])
            for attachment_file in os.listdir(application_attachment_dir):
                esc_attachment_file = wiki_escape_page_title(attachment_file)
                if re.search("^\\d*_Registration.pdf", attachment_file):
                    continue
                cleaned_attachment_file = esc_attachment_file

                attachment_file_display = re.sub("^\\d*_", "", attachment_file)
                attachment_file_display = re.sub("\.pdf$", "", attachment_file_display)
                if len(attachment_file_display) > 33:
                    attachment_file_display = \
                            attachment_file_display[0:15] + \
                            "..." + \
                            attachment_file_display[(len(attachment_file_display)-15):]

                attachments_str += "[[Media:" + cleaned_attachment_file + "|" + attachment_file_display + "]]\n\n"
                attachments_to_add.append("%s|%s" % (
                    esc_attachment_file,
                    os.path.join(application_attachment_dir, attachment_file)))
        new_row.append(attachments_str)

        print("Sanitized row %d (%d cols, %d fixed)." % (row_num, len(new_row), num_fixed_cells), file=sys.stderr)
        new_rows.append(new_row)

    if extra_category_file is not None:
        with open(extra_category_file, 'w') as f:
            f.writelines("%s\n" % extra_cat for extra_cat in extra_cats)

    if attachments_file is not None:
        with open(attachments_file, 'w') as f:
            f.writelines("%s\n" % attachment_pair for attachment_pair in attachments_to_add)

    print_csv(header_row, new_rows)

def main():
    """Compose the MacFound input and emit it as html-ized csv."""
    try:
        opts, args = getopt.getopt(sys.argv[1:], '',
                                   ["pare=",
                                    "proposals-csv=",
                                    "admin-review-csv=",
                                    "judge-evaluation-csv=",
                                    "extra-category-file=",
                                    "attachments-file=",
                                    "attachments-dir=",])
    except getopt.GetoptError as err:
        sys.stderr.write("ERROR: '%s'\n" % err)
        sys.exit(2)

    pare = None
    proposals_csv = None
    admin_review_csv = None
    judge_evaluation_csv = None
    extra_category_file = None
    attachments_file = None
    attachments_dir = None
    for o, a in opts:
        if o == "--pare":
            pare = int(a)
        elif o == "--proposals-csv":
            proposals_csv = a
        elif o == "--admin-review-csv":
            admin_review_csv = a
        elif o == "--judge-evaluation-csv":
            judge_evaluation_csv = a
        elif o == "--extra-category-file":
            extra_category_file = a
        elif o == "--attachments-file":
            attachments_file = a
        elif o == "--attachments-dir":
            attachments_dir = a
        else:
            sys.stderr.write("ERROR: unrecognized option '%s'\n" % o)
            sys.exit(2)

    if (attachments_dir is None) != (attachments_file is None):
        sys.stderr.write(
            "ERROR: need --attachments-dir and --attachments-file, or neither")
        sys.stderr.write(__doc__)
        sys.exit(1)

    if proposals_csv is None or admin_review_csv is None or judge_evaluation_csv is None:
        sys.stderr.write(
            "ERROR: need --proposals-csv, --admin-review-csv, and --judge-evaluation-csv options.\n\n")
        sys.stderr.write(__doc__)
        sys.exit(1)
    compose_csvs(proposals_csv, admin_review_csv, judge_evaluation_csv,
            extra_category_file, attachments_file, attachments_dir, pare)

if __name__ == '__main__':
    main()
